---
title: "classifier"
author: "jason grahn"
date: "5/25/2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(modelr)

set.seed(310)
```

```{r import data}
#load training
training <- read_csv(here::here("data/train_data.csv")) %>% 
  dplyr::select(-contains("X"), -id)

#load testing
testing <- read_csv(here::here("data/test_data.csv")) %>% 
  dplyr::select(-contains("X"), -id) 
```

# Rebuilding models 

## model 1 to find outliers

(this repeats Di's analysis)
```{r build and use model 1}
model.1 <- lm(grad_rate ~ student_count +spending_per_award +full_time_pct
             +full_time_count +med_sat_value +aid_value
             +endow_value +grad_on_time_pct +pell_value +fresh_retain_value
             + full_time_fac_pct,
             data = training)

#remove outliers using model 1
training_without_outliers <- add_residuals(data = training,
                                           model = model.1,
                                           var = "resid") %>% 
  mutate(sdev = sd(resid),
                std.norm = resid / sdev,
                abs.std = abs(std.norm)) %>% #note: 407 rows at this point
   #dplyr::arrange(desc(abs.std)) %>% 
  filter(abs.std < 2)
```

## model 10 to build predictions

```{r rebuild model 10 from the LM}
model.10 <- lm(grad_rate ~ spending_per_award 
               + full_time_count
               + med_sat_value
               + endow_value
               + grad_on_time_pct
               + pell_value
               + fresh_retain_value
             + endow_value*spending_per_award     #EndowXSpend
             + pell_value*med_sat_value           #PellXSat
             + fresh_retain_value*med_sat_value   #RetainXSat
             ,data = training_without_outliers)
```

## putting predictions into training

```{r add predictions back to training set}
training_with_predictions <- add_predictions(training_without_outliers, model.10, var = "pred_grad_rate") %>% 
  add_residuals(model = model.10, var = "resid") %>% 
  #and we dont need these other variables either
  dplyr::select(-sdev, -std.norm, -abs.std) %>% 
  mutate(scaled = scale(pred_grad_rate))
```

## and some plotting with the training data 

This builds out reqs for plotting the testing data. 

```{r}
#and a quick visual of known graduation to predicuted graduation
#training_predictions_scatter <- training_with_predictions %>% 
#  ggplot(aes(x = grad_rate, y = pred_grad_rate)) +
#  geom_point() + 
#  geom_smooth(method = "lm") + 
#  geom_rug() +
#  theme_light()
##################################################
##                                              ##
## ^^^^ TAKE THIS OUT AND PUT IN A QQ PLOT ^^^^ ##
##                                              ##
##################################################

training_QQ <- training_with_predictions %>% 
  ggplot(aes(sample = pred_grad_rate)) +
  stat_qq() +
  theme_light() +
  labs(title = "Training plots...")


training_predictions_boxplot <- training_with_predictions %>% 
  arrange(basic) %>% 
  ggplot(aes(y = pred_grad_rate, x = "x")) +
  geom_boxplot() + 
  geom_jitter(alpha = 0.2, width = .09) +
  theme_light() +
  labs(title = "...do not use for presi")

#histogram of scaled predictions
training_predictions_histogram <- training_with_predictions %>% 
  ggplot() +
  geom_histogram(aes(x = pred_grad_rate), bins = 25) +
  theme_light() 

training_pred_vs_resids <- training_with_predictions %>% 
  ggplot() +
  geom_point(aes(x = pred_grad_rate, y = resid)) +
  theme_light() 

cowplot::plot_grid(training_QQ, 
                   training_predictions_boxplot, 
                   training_predictions_histogram,
                   training_pred_vs_resids,
                   labels = c("1", "2", "3", "4"))
```

1. QQ plot shows generally normal behavior with a few outliers.

2.

3. 

4. 

# Testing

## Application of the model

```{r}
testing_with_predictions <- add_predictions(testing, model = model.10, var = "pred_grad_rate") %>% 
  add_residuals(model = model.10, var = "resid") %>% 
  arrange(pred_grad_rate)
```


```{r}
#and a quick visual of known graduation to predicuted graduation
#testing_predictions_scatter <- testing_with_predictions %>% 
#  ggplot(aes(x = grad_rate, y = pred_grad_rate)) +
#  geom_point() + 
#  geom_smooth(method = "lm") + 
#  geom_rug() +
#  theme_light()
##################################################
##                                              ##
## ^^^^ TAKE THIS OUT AND PUT IN A QQ PLOT ^^^^ ##
##                                              ##
##################################################

testing_QQ <- testing_with_predictions %>% 
  ggplot(aes(sample = pred_grad_rate)) +
  stat_qq() +
  theme_light() +
  labs(title = "QQ Plot")

#histogram of scaled predictions
testing_predictions_histogram <- testing_with_predictions %>% 
  ggplot() +
  geom_histogram(aes(x = pred_grad_rate), bins = 25) +
  theme_light() +
  labs(title = "Boxplot of predicted rates")

#boxplot the predictions
testing_predictions_boxplot <- testing_with_predictions %>% 
  arrange(basic) %>% 
  ggplot(aes(y = pred_grad_rate, x = "x")) +
  geom_boxplot() + 
  geom_jitter(alpha = 0.2, width = .09, color = "darkblue") +
  theme_light() +
  labs(title = "Histogram of predictions")

#scatterplot predictions vs residuals
testing_pred_vs_resids <- testing_with_predictions %>% 
  ggplot() +
  geom_point(aes(x = pred_grad_rate, y = resid)) +
  theme_light() +
  labs(title = "Scatterplot of residuals to predictions")

cowplot::plot_grid(testing_QQ, 
                   testing_predictions_boxplot, 
                   testing_predictions_histogram, 
                   testing_pred_vs_resids,
                   labels = c("1", "2", "3", "4"))
```

1. QQ plot shows generally normal behavior with a few outliers on the top end; much like the training data. 

2. The boxplot provides an additional view of distribution with a tight distribution round the median. 

3. Histogram reinforces normal distribution. 

4. Scatterplot of residuals to predictions is generally equal around zero, with a few outliers. 

# Classification

A classifier should be as simple as possible for the given application. We investigated a variety of methods to automatically find and classify five performance buckets. In the end, the simplest model is also the most easily understood. 

After predicting and scaling graduations rates for each of the colleges in the testing data, we identified that they sit in a generally normal distribution. Using the scaled values of the prediction, we plot a standard normal distribution. [fill this out better]

```{r}
# add classification buckets
testing_with_predictions <- testing_with_predictions %>% 
  mutate(scaled_act = scale(grad_rate), 
         scaled_pred = scale(pred_grad_rate),
         Classifications = factor(case_when(scaled_pred <= (-3) ~ "Poor",
                                           scaled_pred <= (-2) ~ "Below Average",
                                           scaled_pred <= (1) ~ "Average",
                                           scaled_pred <= (2) ~ "Above Average",
                                           scaled_pred > (2) ~ "Excellent"),
                                 levels = c("Excellent", "Above Average", "Average", "Below Average", "Poor"))) 

# build some lines
vlines <- as.matrix(testing_with_predictions %>% 
                      filter(institution_name == "Bellevue College") %>% 
                      select(scaled_pred, scaled_act))

# force coloration
colorlist <- c("chartreuse4", "green3", "ivory4", "orangered2", "darkred")

# visualize the classification
classified_histogram <- testing_with_predictions %>% 
  ggplot() +
  geom_histogram(aes(x = scaled_pred, fill = Classifications), binwidth = .15) +
  geom_vline(aes(xintercept = vlines[1]), color = "blue", size = 1.5) +
  geom_vline(aes(xintercept = vlines[2]), color = "red", size = 1.5) +
  theme_light() +
  theme(legend.position="right") +
  labs(title = "Histogram of Graduation Predictions",
       subtitle = "BC shows Average rates for both actual and prediction",
       x = "Predicted Graduation Rate (scaled)",
       caption = "Red line is BC actual graduation rate,
  Blue line is BC predicted grad rate") +
  scale_fill_manual(values = colorlist)
classified_histogram

ggsave("classified_histogram.jpg")
```



